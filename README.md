# Camera Parameters Learning for Active Object Detection

## Installation
This implementation is based on [FCOS](https://github.com/tianzhi0549/FCOS), [gym](https://github.com/openai/gym) and [keras-rl](https://github.com/keras-rl/keras-rl). This active object detection framework chooses FCOS as object detection module, and chooses Double DQN as camera control module.

## Dataset
Datasets can be downloaded from here. [SA](https://www.dropbox.com/s/jwusmkq90t0cq5f/SA.zip?dl=0)

## Training

### Object Detection Module

    python -m torch.distributed.launch \
        --nproc_per_node=8 \
        --master_port=$((RANDOM + 10000)) \
        tools/train_net.py \
        --config-file configs/fcos/fcos_imprv_R_50_FPN_1x.yaml \
        DATALOADER.NUM_WORKERS 2 \
        OUTPUT_DIR training_dir/fcos_imprv_R_50_FPN_1x

### Camera Control Module
For the simulated airport (SA)

    python tools/train_dqn_vs.py \
        --drl-weights training_dir/ddqn_plane \
        --double

For the virtual park (VP)

    python tools/train_dqn_vsb.py \
        --drl-weights training_dir/ddqn_car \
        --double

## Inference

### Camera Control Module
For the simulated airport (SA)

    python tools/test_dqn_vs.py \
        --drl-weights training_dir/ddqn_plane/dqn_weights_final.h5f \
        --pickle-dir ddqn_plane_search \
        --double

For the virtual park (VP)

    python tools/test_dqn_vsb.py \
        --drl-weights training_dir/ddqn_car/dqn_weights_final.h5f \
        --pickle-dir ddqn_car_search \
        --double

Obtain ground truth of each step for testing according to the corresponding camera parameters. Please modify category and the name of pickle file in get_json.py.

    python tools/get_json.py

### Object Detection Module
For the ground truth of each step generated by get_json.py, use the following command for testing.

    python tools/test_net.py \
        --config-file configs/fcos/fcos_imprv_R_50_FPN_1x.yaml \
        MODEL.WEIGHT FCOS_imprv_R_50_FPN_1x.pth \
        TEST.IMS_PER_BATCH 4
