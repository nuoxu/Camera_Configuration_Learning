# Dynamic Camera Configuration Learning for High-Confidence Active Object Detection (Neurocomputing 2021)

## Installation
This implementation is based on [FCOS](https://github.com/tianzhi0549/FCOS), [gym](https://github.com/openai/gym) and [keras-rl](https://github.com/keras-rl/keras-rl). This active object detection framework chooses FCOS as object detection module, and chooses Double DQN as camera control module.

## Dataset
Download address of two datasets : [SA](https://www.kaggle.com/datasets/hellob/sa-and-vp?select=SA) and [VP](https://www.kaggle.com/datasets/hellob/sa-and-vp?select=VP).

## Training

### Object Detection Module

    python -m torch.distributed.launch \
        --nproc_per_node=8 \
        --master_port=$((RANDOM + 10000)) \
        tools/train_net.py \
        --config-file configs/fcos/fcos_imprv_R_50_FPN_1x.yaml \
        DATALOADER.NUM_WORKERS 2 \
        OUTPUT_DIR training_dir/fcos_imprv_R_50_FPN_1x

### Camera Control Module
For the simulated airport (SA)

    python tools/train_dqn_vs.py \
        --drl-weights training_dir/ddqn_plane \
        --double

For the virtual park (VP)

    python tools/train_dqn_vsb.py \
        --drl-weights training_dir/ddqn_car \
        --double

## Inference

### Camera Control Module
For the simulated airport (SA)

    python tools/test_dqn_vs.py \
        --drl-weights training_dir/ddqn_plane/dqn_weights_final.h5f \
        --pickle-dir ddqn_plane_search \
        --double

For the virtual park (VP)

    python tools/test_dqn_vsb.py \
        --drl-weights training_dir/ddqn_car/dqn_weights_final.h5f \
        --pickle-dir ddqn_car_search \
        --double

Obtain ground truth of each step for testing according to the corresponding camera parameters. Please modify category and the name of pickle file in get_json.py.

    python tools/get_json.py

### Object Detection Module
For the ground truth of each step generated by get_json.py, use the following command for testing.

    python tools/test_net.py \
        --config-file configs/fcos/fcos_imprv_R_50_FPN_1x.yaml \
        MODEL.WEIGHT FCOS_imprv_R_50_FPN_1x.pth \
        TEST.IMS_PER_BATCH 4

You can cite our paper as:
```
@article{xu2021dynamic,
  title={Dynamic camera configuration learning for high-confidence active object detection},
  author={Xu, Nuo and Huo, Chunlei and Zhang, Xin and Cao, Yong and Meng, Gaofeng and Pan, Chunhong},
  journal={Neurocomputing},
  volume={466},
  pages={113--127},
  year={2021},
  publisher={Elsevier}
}
```
